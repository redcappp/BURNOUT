{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":104857,"databundleVersionId":12651513,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-14T14:00:37.087146Z","iopub.execute_input":"2025-06-14T14:00:37.087408Z","iopub.status.idle":"2025-06-14T14:00:37.410420Z","shell.execute_reply.started":"2025-06-14T14:00:37.087390Z","shell.execute_reply":"2025-06-14T14:00:37.409675Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_df=pd.read_csv(\"/kaggle/input/burnout-datathon-ieeecsmuj/train.csv\")\ntest_df=pd.read_csv(\"/kaggle/input/burnout-datathon-ieeecsmuj/test.csv\")\nval_df=pd.read_csv(\"/kaggle/input/burnout-datathon-ieeecsmuj/val.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T06:45:23.804562Z","iopub.execute_input":"2025-06-14T06:45:23.805024Z","iopub.status.idle":"2025-06-14T06:45:49.417348Z","shell.execute_reply.started":"2025-06-14T06:45:23.804998Z","shell.execute_reply":"2025-06-14T06:45:49.416487Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_df = pd.concat([train_df, val_df], ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T06:45:49.418640Z","iopub.execute_input":"2025-06-14T06:45:49.418929Z","iopub.status.idle":"2025-06-14T06:45:49.969958Z","shell.execute_reply.started":"2025-06-14T06:45:49.418896Z","shell.execute_reply":"2025-06-14T06:45:49.969081Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"key_cols = ['Rider_ID', 'Bike', 'Team', 'Circuit_name']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T06:45:55.149027Z","iopub.execute_input":"2025-06-14T06:45:55.149333Z","iopub.status.idle":"2025-06-14T06:45:55.154093Z","shell.execute_reply.started":"2025-06-14T06:45:55.149309Z","shell.execute_reply":"2025-06-14T06:45:55.152889Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_df.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T06:47:49.145111Z","iopub.execute_input":"2025-06-14T06:47:49.145391Z","iopub.status.idle":"2025-06-14T06:47:49.154971Z","shell.execute_reply.started":"2025-06-14T06:47:49.145372Z","shell.execute_reply":"2025-06-14T06:47:49.154076Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Unique ID                            int64\nRider_ID                            object\ncategory_x                          object\nCircuit_Length_km                  float64\nLaps                                 int64\nGrid_Position                        int64\nAvg_Speed_kmh                      float64\nTrack_Condition                     object\nHumidity_%                           int64\nTire_Compound_Front                 object\nTire_Compound_Rear                  object\nPenalty                             object\nChampionship_Points                  int64\nChampionship_Position                int64\nSession                             object\nyear_x                               int64\nsequence                             int64\nrider                                int64\nteam                                 int64\nbike                                 int64\nposition                             int64\npoints                             float64\nshortname                           object\ncircuit_name                        object\nrider_name                          object\nteam_name                           object\nbike_name                           object\nLap_Time_Seconds                   float64\nCorners_per_Lap                      int64\nTire_Degradation_Factor_per_Lap    float64\nPit_Stop_Duration_Seconds          float64\nAmbient_Temperature_Celsius        float64\nTrack_Temperature_Celsius          float64\nweather                             object\ntrack                               object\nair                                  int64\nground                               int64\nstarts                               int64\nfinishes                             int64\nwith_points                          int64\npodiums                              int64\nwins                                 int64\nmin_year                             int64\nmax_year                             int64\nyears_active                         int64\ndtype: object"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# Convert key columns to string\nkey_cols = ['rider', 'bike', 'team', 'circuit_name']\n\nfor col in key_cols:\n    train_df[col] = train_df[col].astype(str)\n    test_df[col] = test_df[col].astype(str)\n\n# Create composite key\ntrain_df['key'] = train_df[key_cols].agg('_'.join, axis=1)\ntest_df['key'] = test_df[key_cols].agg('_'.join, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T07:10:11.208681Z","iopub.execute_input":"2025-06-14T07:10:11.209062Z","iopub.status.idle":"2025-06-14T07:10:26.662858Z","shell.execute_reply.started":"2025-06-14T07:10:11.209035Z","shell.execute_reply":"2025-06-14T07:10:26.661946Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Step 1: Compute average Lap_Time_Seconds for each key from train_df\nkey_to_avg_lap_time = train_df.groupby('key')['Lap_Time_Seconds'].mean()\n\n# Step 2: Map this to test_df based on the key\ntest_df['calc_lap_time'] = test_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Count NaN values\nnum_nan = test_df['calc_lap_time'].isna().sum()\n\nprint(f\"‚ùå Number of NaN values in test_df['calc_lap_time']: {num_nan}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T07:10:30.426897Z","iopub.execute_input":"2025-06-14T07:10:30.427223Z","iopub.status.idle":"2025-06-14T07:10:31.394802Z","shell.execute_reply.started":"2025-06-14T07:10:30.427202Z","shell.execute_reply":"2025-06-14T07:10:31.393651Z"}},"outputs":[{"name":"stdout","text":"‚ùå Number of NaN values in test_df['calc_lap_time']: 0\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"train_df['calc_lap_time'] = train_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Compute RMSE between predicted and actual\nrmse_key_mean = mean_squared_error(train_df['Lap_Time_Seconds'], train_df['calc_lap_time'], squared=False)\n\n# Step 4: Print result\nprint(f\"üìè RMSE using group mean by key in train_df: {rmse_key_mean:.4f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T07:14:31.584645Z","iopub.execute_input":"2025-06-14T07:14:31.585007Z","iopub.status.idle":"2025-06-14T07:14:32.267466Z","shell.execute_reply.started":"2025-06-14T07:14:31.584987Z","shell.execute_reply":"2025-06-14T07:14:32.266467Z"}},"outputs":[{"name":"stdout","text":"üìè RMSE using group mean by key in train_df: 6.2290 seconds\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Convert key columns to string\nkey_cols = ['rider', 'bike', 'team', 'circuit_name','sequence']\n\nfor col in key_cols:\n    train_df[col] = train_df[col].astype(str)\n    test_df[col] = test_df[col].astype(str)\n\n# Create composite key\ntrain_df['key'] = train_df[key_cols].agg('_'.join, axis=1)\ntest_df['key'] = test_df[key_cols].agg('_'.join, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T07:17:38.112137Z","iopub.execute_input":"2025-06-14T07:17:38.112539Z","iopub.status.idle":"2025-06-14T07:17:53.726474Z","shell.execute_reply.started":"2025-06-14T07:17:38.112513Z","shell.execute_reply":"2025-06-14T07:17:53.725496Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Step 1: Compute average Lap_Time_Seconds for each key from train_df\nkey_to_avg_lap_time = train_df.groupby('key')['Lap_Time_Seconds'].mean()\n\n# Step 2: Map this to test_df based on the key\ntest_df['calc_lap_time'] = test_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Count NaN values\nnum_nan = test_df['calc_lap_time'].isna().sum()\n\nprint(f\"‚ùå Number of NaN values in test_df['calc_lap_time']: {num_nan}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T07:17:56.496053Z","iopub.execute_input":"2025-06-14T07:17:56.496386Z","iopub.status.idle":"2025-06-14T07:17:57.443032Z","shell.execute_reply.started":"2025-06-14T07:17:56.496363Z","shell.execute_reply":"2025-06-14T07:17:57.441816Z"}},"outputs":[{"name":"stdout","text":"‚ùå Number of NaN values in test_df['calc_lap_time']: 0\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"train_df['calc_lap_time'] = train_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Compute RMSE between predicted and actual\nrmse_key_mean = mean_squared_error(train_df['Lap_Time_Seconds'], train_df['calc_lap_time'], squared=False)\n\n# Step 4: Print result\nprint(f\"üìè RMSE using group mean by key in train_df: {rmse_key_mean:.4f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T07:18:12.570530Z","iopub.execute_input":"2025-06-14T07:18:12.570919Z","iopub.status.idle":"2025-06-14T07:18:13.289353Z","shell.execute_reply.started":"2025-06-14T07:18:12.570896Z","shell.execute_reply":"2025-06-14T07:18:13.288268Z"}},"outputs":[{"name":"stdout","text":"üìè RMSE using group mean by key in train_df: 4.3881 seconds\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Convert key columns to string\nkey_cols = ['rider', 'bike', 'team', 'circuit_name','sequence','year_x']\n\nfor col in key_cols:\n    train_df[col] = train_df[col].astype(str)\n    test_df[col] = test_df[col].astype(str)\n\n# Create composite key\ntrain_df['key'] = train_df[key_cols].agg('_'.join, axis=1)\ntest_df['key'] = test_df[key_cols].agg('_'.join, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T07:34:53.579853Z","iopub.execute_input":"2025-06-14T07:34:53.580306Z","iopub.status.idle":"2025-06-14T07:35:09.685544Z","shell.execute_reply.started":"2025-06-14T07:34:53.580279Z","shell.execute_reply":"2025-06-14T07:35:09.684219Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Step 1: Compute average Lap_Time_Seconds for each key from train_df\nkey_to_avg_lap_time = train_df.groupby('key')['Lap_Time_Seconds'].mean()\n\n# Step 2: Map this to test_df based on the key\ntest_df['calc_lap_time'] = test_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Count NaN values\nnum_nan = test_df['calc_lap_time'].isna().sum()\n\nprint(f\"‚ùå Number of NaN values in test_df['calc_lap_time']: {num_nan}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T07:35:11.572719Z","iopub.execute_input":"2025-06-14T07:35:11.573080Z","iopub.status.idle":"2025-06-14T07:35:12.736025Z","shell.execute_reply.started":"2025-06-14T07:35:11.573058Z","shell.execute_reply":"2025-06-14T07:35:12.735150Z"}},"outputs":[{"name":"stdout","text":"‚ùå Number of NaN values in test_df['calc_lap_time']: 0\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"train_df['calc_lap_time'] = train_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Compute RMSE between predicted and actual\nrmse_key_mean = mean_squared_error(train_df['Lap_Time_Seconds'], train_df['calc_lap_time'], squared=False)\n\n# Step 4: Print result\nprint(f\"üìè RMSE using group mean by key in train_df: {rmse_key_mean:.4f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T07:35:22.499226Z","iopub.execute_input":"2025-06-14T07:35:22.499588Z","iopub.status.idle":"2025-06-14T07:35:23.313374Z","shell.execute_reply.started":"2025-06-14T07:35:22.499564Z","shell.execute_reply":"2025-06-14T07:35:23.312556Z"}},"outputs":[{"name":"stdout","text":"üìè RMSE using group mean by key in train_df: 1.7009 seconds\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Convert key columns to string\nkey_cols = ['rider', 'bike', 'team', 'circuit_name','sequence','year_x','category_x']\n\nfor col in key_cols:\n    train_df[col] = train_df[col].astype(str)\n    test_df[col] = test_df[col].astype(str)\n\n# Create composite key\ntrain_df['key'] = train_df[key_cols].agg('_'.join, axis=1)\ntest_df['key'] = test_df[key_cols].agg('_'.join, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T07:43:12.993997Z","iopub.execute_input":"2025-06-14T07:43:12.994313Z","iopub.status.idle":"2025-06-14T07:43:28.844010Z","shell.execute_reply.started":"2025-06-14T07:43:12.994293Z","shell.execute_reply":"2025-06-14T07:43:28.842772Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Step 1: Compute average Lap_Time_Seconds for each key from train_df\nkey_to_avg_lap_time = train_df.groupby('key')['Lap_Time_Seconds'].mean()\n\n# Step 2: Map this to test_df based on the key\ntest_df['calc_lap_time'] = test_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Count NaN values\nnum_nan = test_df['calc_lap_time'].isna().sum()\n\nprint(f\"‚ùå Number of NaN values in test_df['calc_lap_time']: {num_nan}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T07:43:41.916486Z","iopub.execute_input":"2025-06-14T07:43:41.916881Z","iopub.status.idle":"2025-06-14T07:43:43.624679Z","shell.execute_reply.started":"2025-06-14T07:43:41.916856Z","shell.execute_reply":"2025-06-14T07:43:43.623663Z"}},"outputs":[{"name":"stdout","text":"‚ùå Number of NaN values in test_df['calc_lap_time']: 0\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"train_df['calc_lap_time'] = train_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Compute RMSE between predicted and actual\nrmse_key_mean = mean_squared_error(train_df['Lap_Time_Seconds'], train_df['calc_lap_time'], squared=False)\n\n# Step 4: Print result\nprint(f\"üìè RMSE using group mean by key in train_df: {rmse_key_mean:.4f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T07:43:46.499073Z","iopub.execute_input":"2025-06-14T07:43:46.499399Z","iopub.status.idle":"2025-06-14T07:43:47.617021Z","shell.execute_reply.started":"2025-06-14T07:43:46.499377Z","shell.execute_reply":"2025-06-14T07:43:47.616187Z"}},"outputs":[{"name":"stdout","text":"üìè RMSE using group mean by key in train_df: 1.6784 seconds\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Convert key columns to string\nkey_cols = ['rider', 'bike', 'team', 'circuit_name','sequence','year_x','category_x','Tire_Compound_Front','Tire_Compound_Rear']\n\nfor col in key_cols:\n    train_df[col] = train_df[col].astype(str)\n    test_df[col] = test_df[col].astype(str)\n\n# Create composite key\ntrain_df['key'] = train_df[key_cols].agg('_'.join, axis=1)\ntest_df['key'] = test_df[key_cols].agg('_'.join, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T07:45:31.894415Z","iopub.execute_input":"2025-06-14T07:45:31.894969Z","iopub.status.idle":"2025-06-14T07:45:48.956118Z","shell.execute_reply.started":"2025-06-14T07:45:31.894943Z","shell.execute_reply":"2025-06-14T07:45:48.955033Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# Step 1: Compute average Lap_Time_Seconds for each key from train_df\nkey_to_avg_lap_time = train_df.groupby('key')['Lap_Time_Seconds'].mean()\n\n# Step 2: Map this to test_df based on the key\ntest_df['calc_lap_time'] = test_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Count NaN values\nnum_nan = test_df['calc_lap_time'].isna().sum()\n\nprint(f\"‚ùå Number of NaN values in test_df['calc_lap_time']: {num_nan}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T07:45:50.848903Z","iopub.execute_input":"2025-06-14T07:45:50.849199Z","iopub.status.idle":"2025-06-14T07:45:56.182243Z","shell.execute_reply.started":"2025-06-14T07:45:50.849180Z","shell.execute_reply":"2025-06-14T07:45:56.181338Z"}},"outputs":[{"name":"stdout","text":"‚ùå Number of NaN values in test_df['calc_lap_time']: 125306\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"train_df['calc_lap_time'] = train_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Compute RMSE between predicted and actual\nrmse_key_mean = mean_squared_error(train_df['Lap_Time_Seconds'], train_df['calc_lap_time'], squared=False)\n\n# Step 4: Print result\nprint(f\"üìè RMSE using group mean by key in train_df: {rmse_key_mean:.4f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T07:46:06.665729Z","iopub.execute_input":"2025-06-14T07:46:06.666086Z","iopub.status.idle":"2025-06-14T07:46:07.653644Z","shell.execute_reply.started":"2025-06-14T07:46:06.666062Z","shell.execute_reply":"2025-06-14T07:46:07.652595Z"}},"outputs":[{"name":"stdout","text":"üìè RMSE using group mean by key in train_df: 1.4126 seconds\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# Convert key columns to string\nkey_cols = ['rider', 'bike', 'team', 'circuit_name','sequence','year_x','category_x','position']\n\nfor col in key_cols:\n    train_df[col] = train_df[col].astype(str)\n    test_df[col] = test_df[col].astype(str)\n\n# Create composite key\ntrain_df['key'] = train_df[key_cols].agg('_'.join, axis=1)\ntest_df['key'] = test_df[key_cols].agg('_'.join, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T07:47:55.346199Z","iopub.execute_input":"2025-06-14T07:47:55.346663Z","iopub.status.idle":"2025-06-14T07:48:12.339441Z","shell.execute_reply.started":"2025-06-14T07:47:55.346630Z","shell.execute_reply":"2025-06-14T07:48:12.338347Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# Step 1: Compute average Lap_Time_Seconds for each key from train_df\nkey_to_avg_lap_time = train_df.groupby('key')['Lap_Time_Seconds'].mean()\n\n# Step 2: Map this to test_df based on the key\ntest_df['calc_lap_time'] = test_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Count NaN values\nnum_nan = test_df['calc_lap_time'].isna().sum()\n\nprint(f\"‚ùå Number of NaN values in test_df['calc_lap_time']: {num_nan}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T07:48:26.779501Z","iopub.execute_input":"2025-06-14T07:48:26.779804Z","iopub.status.idle":"2025-06-14T07:48:28.537756Z","shell.execute_reply.started":"2025-06-14T07:48:26.779785Z","shell.execute_reply":"2025-06-14T07:48:28.536695Z"}},"outputs":[{"name":"stdout","text":"‚ùå Number of NaN values in test_df['calc_lap_time']: 0\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"train_df['calc_lap_time'] = train_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Compute RMSE between predicted and actual\nrmse_key_mean = mean_squared_error(train_df['Lap_Time_Seconds'], train_df['calc_lap_time'], squared=False)\n\n# Step 4: Print result\nprint(f\"üìè RMSE using group mean by key in train_df: {rmse_key_mean:.4f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T07:48:40.687257Z","iopub.execute_input":"2025-06-14T07:48:40.687606Z","iopub.status.idle":"2025-06-14T07:48:41.810825Z","shell.execute_reply.started":"2025-06-14T07:48:40.687576Z","shell.execute_reply":"2025-06-14T07:48:41.809850Z"}},"outputs":[{"name":"stdout","text":"üìè RMSE using group mean by key in train_df: 0.8337 seconds\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# Convert key columns to string\nkey_cols = ['rider', 'bike', 'team', 'circuit_name','sequence','year_x','category_x','position','Grid_Position']\n\nfor col in key_cols:\n    train_df[col] = train_df[col].astype(str)\n    test_df[col] = test_df[col].astype(str)\n\n# Create composite key\ntrain_df['key'] = train_df[key_cols].agg('_'.join, axis=1)\ntest_df['key'] = test_df[key_cols].agg('_'.join, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T08:01:41.141878Z","iopub.execute_input":"2025-06-14T08:01:41.142284Z","iopub.status.idle":"2025-06-14T08:01:59.156690Z","shell.execute_reply.started":"2025-06-14T08:01:41.142259Z","shell.execute_reply":"2025-06-14T08:01:59.155745Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# Step 1: Compute average Lap_Time_Seconds for each key from train_df\nkey_to_avg_lap_time = train_df.groupby('key')['Lap_Time_Seconds'].mean()\n\n# Step 2: Map this to test_df based on the key\ntest_df['calc_lap_time'] = test_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Count NaN values\nnum_nan = test_df['calc_lap_time'].isna().sum()\n\nprint(f\"‚ùå Number of NaN values in test_df['calc_lap_time']: {num_nan}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T08:02:15.147304Z","iopub.execute_input":"2025-06-14T08:02:15.148002Z","iopub.status.idle":"2025-06-14T08:02:23.549144Z","shell.execute_reply.started":"2025-06-14T08:02:15.147972Z","shell.execute_reply":"2025-06-14T08:02:23.547531Z"}},"outputs":[{"name":"stdout","text":"‚ùå Number of NaN values in test_df['calc_lap_time']: 302169\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"train_df['calc_lap_time'] = train_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Compute RMSE between predicted and actual\nrmse_key_mean = mean_squared_error(train_df['Lap_Time_Seconds'], train_df['calc_lap_time'], squared=False)\n\n# Step 4: Print result\nprint(f\"üìè RMSE using group mean by key in train_df: {rmse_key_mean:.4f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T08:04:29.359133Z","iopub.execute_input":"2025-06-14T08:04:29.359553Z","iopub.status.idle":"2025-06-14T08:04:30.118163Z","shell.execute_reply.started":"2025-06-14T08:04:29.359527Z","shell.execute_reply":"2025-06-14T08:04:30.116944Z"}},"outputs":[{"name":"stdout","text":"üìè RMSE using group mean by key in train_df: 0.5497 seconds\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# Convert key columns to string\nkey_cols = ['rider', 'bike', 'team', 'circuit_name','sequence','year_x','category_x','position','Track_Condition']\n\nfor col in key_cols:\n    train_df[col] = train_df[col].astype(str)\n    test_df[col] = test_df[col].astype(str)\n\n# Create composite key\ntrain_df['key'] = train_df[key_cols].agg('_'.join, axis=1)\ntest_df['key'] = test_df[key_cols].agg('_'.join, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T08:05:18.348371Z","iopub.execute_input":"2025-06-14T08:05:18.348782Z","iopub.status.idle":"2025-06-14T08:05:35.433457Z","shell.execute_reply.started":"2025-06-14T08:05:18.348757Z","shell.execute_reply":"2025-06-14T08:05:35.432253Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# Step 1: Compute average Lap_Time_Seconds for each key from train_df\nkey_to_avg_lap_time = train_df.groupby('key')['Lap_Time_Seconds'].mean()\n\n# Step 2: Map this to test_df based on the key\ntest_df['calc_lap_time'] = test_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Count NaN values\nnum_nan = test_df['calc_lap_time'].isna().sum()\n\nprint(f\"‚ùå Number of NaN values in test_df['calc_lap_time']: {num_nan}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T08:05:37.483884Z","iopub.execute_input":"2025-06-14T08:05:37.484227Z","iopub.status.idle":"2025-06-14T08:05:39.934115Z","shell.execute_reply.started":"2025-06-14T08:05:37.484196Z","shell.execute_reply":"2025-06-14T08:05:39.933250Z"}},"outputs":[{"name":"stdout","text":"‚ùå Number of NaN values in test_df['calc_lap_time']: 873\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"train_df['calc_lap_time'] = train_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Compute RMSE between predicted and actual\nrmse_key_mean = mean_squared_error(train_df['Lap_Time_Seconds'], train_df['calc_lap_time'], squared=False)\n\n# Step 4: Print result\nprint(f\"üìè RMSE using group mean by key in train_df: {rmse_key_mean:.4f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T08:05:47.981383Z","iopub.execute_input":"2025-06-14T08:05:47.981759Z","iopub.status.idle":"2025-06-14T08:05:49.223739Z","shell.execute_reply.started":"2025-06-14T08:05:47.981730Z","shell.execute_reply":"2025-06-14T08:05:49.222601Z"}},"outputs":[{"name":"stdout","text":"üìè RMSE using group mean by key in train_df: 0.8157 seconds\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"# Convert key columns to string\nkey_cols = ['rider', 'bike', 'team', 'circuit_name','sequence','year_x','category_x','position','weather']\n\nfor col in key_cols:\n    train_df[col] = train_df[col].astype(str)\n    test_df[col] = test_df[col].astype(str)\n\n# Create composite key\ntrain_df['key'] = train_df[key_cols].agg('_'.join, axis=1)\ntest_df['key'] = test_df[key_cols].agg('_'.join, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T08:07:19.301567Z","iopub.execute_input":"2025-06-14T08:07:19.302206Z","iopub.status.idle":"2025-06-14T08:07:36.715701Z","shell.execute_reply.started":"2025-06-14T08:07:19.302176Z","shell.execute_reply":"2025-06-14T08:07:36.714477Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# Step 1: Compute average Lap_Time_Seconds for each key from train_df\nkey_to_avg_lap_time = train_df.groupby('key')['Lap_Time_Seconds'].mean()\n\n# Step 2: Map this to test_df based on the key\ntest_df['calc_lap_time'] = test_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Count NaN values\nnum_nan = test_df['calc_lap_time'].isna().sum()\n\nprint(f\"‚ùå Number of NaN values in test_df['calc_lap_time']: {num_nan}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T08:07:41.339294Z","iopub.execute_input":"2025-06-14T08:07:41.339650Z","iopub.status.idle":"2025-06-14T08:07:43.178732Z","shell.execute_reply.started":"2025-06-14T08:07:41.339627Z","shell.execute_reply":"2025-06-14T08:07:43.177407Z"}},"outputs":[{"name":"stdout","text":"‚ùå Number of NaN values in test_df['calc_lap_time']: 0\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"train_df['calc_lap_time'] = train_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Compute RMSE between predicted and actual\nrmse_key_mean = mean_squared_error(train_df['Lap_Time_Seconds'], train_df['calc_lap_time'], squared=False)\n\n# Step 4: Print result\nprint(f\"üìè RMSE using group mean by key in train_df: {rmse_key_mean:.4f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T08:07:57.043131Z","iopub.execute_input":"2025-06-14T08:07:57.043467Z","iopub.status.idle":"2025-06-14T08:07:58.221431Z","shell.execute_reply.started":"2025-06-14T08:07:57.043411Z","shell.execute_reply":"2025-06-14T08:07:58.220411Z"}},"outputs":[{"name":"stdout","text":"üìè RMSE using group mean by key in train_df: 0.8337 seconds\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"# Convert key columns to string\nkey_cols = ['rider', 'bike', 'team', 'circuit_name','sequence','year_x','category_x','position','weather','track']\n\nfor col in key_cols:\n    train_df[col] = train_df[col].astype(str)\n    test_df[col] = test_df[col].astype(str)\n\n# Create composite key\ntrain_df['key'] = train_df[key_cols].agg('_'.join, axis=1)\ntest_df['key'] = test_df[key_cols].agg('_'.join, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T08:11:39.366227Z","iopub.execute_input":"2025-06-14T08:11:39.366612Z","iopub.status.idle":"2025-06-14T08:11:57.097459Z","shell.execute_reply.started":"2025-06-14T08:11:39.366588Z","shell.execute_reply":"2025-06-14T08:11:57.096360Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"# Step 1: Compute average Lap_Time_Seconds for each key from train_df\nkey_to_avg_lap_time = train_df.groupby('key')['Lap_Time_Seconds'].mean()\n\n# Step 2: Map this to test_df based on the key\ntest_df['calc_lap_time'] = test_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Count NaN values\nnum_nan = test_df['calc_lap_time'].isna().sum()\n\nprint(f\"‚ùå Number of NaN values in test_df['calc_lap_time']: {num_nan}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T08:11:57.099047Z","iopub.execute_input":"2025-06-14T08:11:57.099379Z","iopub.status.idle":"2025-06-14T08:11:59.051068Z","shell.execute_reply.started":"2025-06-14T08:11:57.099347Z","shell.execute_reply":"2025-06-14T08:11:59.050129Z"}},"outputs":[{"name":"stdout","text":"‚ùå Number of NaN values in test_df['calc_lap_time']: 0\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"train_df['calc_lap_time'] = train_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Compute RMSE between predicted and actual\nrmse_key_mean = mean_squared_error(train_df['Lap_Time_Seconds'], train_df['calc_lap_time'], squared=False)\n\n# Step 4: Print result\nprint(f\"üìè RMSE using group mean by key in train_df: {rmse_key_mean:.4f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T08:12:22.597816Z","iopub.execute_input":"2025-06-14T08:12:22.598147Z","iopub.status.idle":"2025-06-14T08:12:23.745404Z","shell.execute_reply.started":"2025-06-14T08:12:22.598123Z","shell.execute_reply":"2025-06-14T08:12:23.744577Z"}},"outputs":[{"name":"stdout","text":"üìè RMSE using group mean by key in train_df: 0.8337 seconds\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"train_df=pd.read_csv(\"/kaggle/input/burnout-datathon-ieeecsmuj/train.csv\")\ntest_df=pd.read_csv(\"/kaggle/input/burnout-datathon-ieeecsmuj/test.csv\")\nval_df=pd.read_csv(\"/kaggle/input/burnout-datathon-ieeecsmuj/val.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T14:03:02.689361Z","iopub.execute_input":"2025-06-14T14:03:02.690359Z","iopub.status.idle":"2025-06-14T14:03:26.469750Z","shell.execute_reply.started":"2025-06-14T14:03:02.690326Z","shell.execute_reply":"2025-06-14T14:03:26.468919Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_df = pd.concat([train_df, val_df], ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T14:03:30.275597Z","iopub.execute_input":"2025-06-14T14:03:30.276470Z","iopub.status.idle":"2025-06-14T14:03:30.761672Z","shell.execute_reply.started":"2025-06-14T14:03:30.276442Z","shell.execute_reply":"2025-06-14T14:03:30.760839Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Convert key columns to string\nkey_cols = ['rider','circuit_name', 'year_x',\n     'Corners_per_Lap', 'Pit_Stop_Duration_Seconds']\n\nfor col in key_cols:\n    train_df[col] = train_df[col].astype(str)\n    test_df[col] = test_df[col].astype(str)\n\n# Create composite key\ntrain_df['key'] = train_df[key_cols].agg('_'.join, axis=1)\ntest_df['key'] = test_df[key_cols].agg('_'.join, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T14:03:31.890438Z","iopub.execute_input":"2025-06-14T14:03:31.890760Z","iopub.status.idle":"2025-06-14T14:03:49.164345Z","shell.execute_reply.started":"2025-06-14T14:03:31.890735Z","shell.execute_reply":"2025-06-14T14:03:49.163462Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Step 1: Compute average Lap_Time_Seconds for each key from train_df\nkey_to_avg_lap_time = train_df.groupby('key')['Lap_Time_Seconds'].mean()\n\n# Step 2: Map this to test_df based on the key\ntest_df['calc_lap_time'] = test_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Count NaN values\nnum_nan = test_df['calc_lap_time'].isna().sum()\n\nprint(f\"‚ùå Number of NaN values in test_df['calc_lap_time']: {num_nan}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T14:03:52.019299Z","iopub.execute_input":"2025-06-14T14:03:52.019575Z","iopub.status.idle":"2025-06-14T14:03:52.992919Z","shell.execute_reply.started":"2025-06-14T14:03:52.019555Z","shell.execute_reply":"2025-06-14T14:03:52.991962Z"}},"outputs":[{"name":"stdout","text":"‚ùå Number of NaN values in test_df['calc_lap_time']: 0\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\ntrain_df['calc_lap_time'] = train_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Compute RMSE between predicted and actual\nrmse_key_mean = mean_squared_error(train_df['Lap_Time_Seconds'], train_df['calc_lap_time'], squared=False)\n\n# Step 4: Print result\nprint(f\"üìè RMSE using group mean by key in train_df: {rmse_key_mean:.4f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T14:03:54.718303Z","iopub.execute_input":"2025-06-14T14:03:54.718630Z","iopub.status.idle":"2025-06-14T14:03:56.083762Z","shell.execute_reply.started":"2025-06-14T14:03:54.718577Z","shell.execute_reply":"2025-06-14T14:03:56.082873Z"}},"outputs":[{"name":"stdout","text":"üìè RMSE using group mean by key in train_df: 0.0000 seconds\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Step 1: Compute mean Lap_Time_Seconds for each key\nkey_to_avg_lap_time = train_df.groupby('key')['Lap_Time_Seconds'].mean()\n\n# Step 2: Map to test_df\ntest_df['Lap_Time_Seconds'] = test_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Handle missing keys (optional: fill with global mean or median)\nglobal_mean = train_df['Lap_Time_Seconds'].mean()\ntest_df['Lap_Time_Seconds'] = test_df['Lap_Time_Seconds'].fillna(global_mean)\n\n# Step 4: Create submission DataFrame\nsubmission = test_df[['Unique ID', 'Lap_Time_Seconds']]\n\n# Step 5: Save to CSV\nsubmission.to_csv('submission.csv', index=False)\n\nprint(\"‚úÖ Submission file 'submission.csv' created.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T14:04:00.321387Z","iopub.execute_input":"2025-06-14T14:04:00.321835Z","iopub.status.idle":"2025-06-14T14:04:02.149464Z","shell.execute_reply.started":"2025-06-14T14:04:00.321810Z","shell.execute_reply":"2025-06-14T14:04:02.148515Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Submission file 'submission.csv' created.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"submission.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T14:06:27.516792Z","iopub.execute_input":"2025-06-14T14:06:27.517099Z","iopub.status.idle":"2025-06-14T14:06:27.528098Z","shell.execute_reply.started":"2025-06-14T14:06:27.517079Z","shell.execute_reply":"2025-06-14T14:06:27.527284Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Unique ID           0\nLap_Time_Seconds    0\ndtype: int64"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"train_df=pd.read_csv(\"/kaggle/input/burnout-datathon-ieeecsmuj/train.csv\")\ntest_df=pd.read_csv(\"/kaggle/input/burnout-datathon-ieeecsmuj/test.csv\")\nval_df=pd.read_csv(\"/kaggle/input/burnout-datathon-ieeecsmuj/val.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T12:57:59.919125Z","iopub.execute_input":"2025-06-14T12:57:59.919595Z","iopub.status.idle":"2025-06-14T12:58:17.260886Z","shell.execute_reply.started":"2025-06-14T12:57:59.919566Z","shell.execute_reply":"2025-06-14T12:58:17.259756Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"train_df = pd.concat([train_df, val_df], ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T12:58:17.263180Z","iopub.execute_input":"2025-06-14T12:58:17.263568Z","iopub.status.idle":"2025-06-14T12:58:17.555724Z","shell.execute_reply.started":"2025-06-14T12:58:17.263533Z","shell.execute_reply":"2025-06-14T12:58:17.554750Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"# Convert key columns to string\nkey_cols = ['rider','bike','shortname','circuit_name','year_x','Session','sequence','position','points','Corners_per_Lap','Pit_Stop_Duration_Seconds']\n\nfor col in key_cols:\n    train_df[col] = train_df[col].astype(str)\n    test_df[col] = test_df[col].astype(str)\n\n# Create composite key\ntrain_df['key'] = train_df[key_cols].agg('_'.join, axis=1)\ntest_df['key'] = test_df[key_cols].agg('_'.join, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T12:52:11.093465Z","iopub.status.idle":"2025-06-14T12:52:11.093863Z","shell.execute_reply.started":"2025-06-14T12:52:11.093699Z","shell.execute_reply":"2025-06-14T12:52:11.093714Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1: Compute average Lap_Time_Seconds for each key from train_df\nkey_to_avg_lap_time = train_df.groupby('key')['Lap_Time_Seconds'].mean()\n\n# Step 2: Map this to test_df based on the key\ntest_df['calc_lap_time'] = test_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Count NaN values\nnum_nan = test_df['calc_lap_time'].isna().sum()\n\nprint(f\"‚ùå Number of NaN values in test_df['calc_lap_time']: {num_nan}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T12:52:11.096990Z","iopub.status.idle":"2025-06-14T12:52:11.097566Z","shell.execute_reply.started":"2025-06-14T12:52:11.097289Z","shell.execute_reply":"2025-06-14T12:52:11.097311Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\n\ntrain_df['calc_lap_time'] = train_df['key'].map(key_to_avg_lap_time)\n\n# Step 3: Compute RMSE between predicted and actual\nrmse_key_mean = mean_squared_error(train_df['Lap_Time_Seconds'], train_df['calc_lap_time'], squared=False)\n\n# Step 4: Print result\nprint(f\"üìè RMSE using group mean by key in train_df: {rmse_key_mean:.4f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T12:52:11.098921Z","iopub.status.idle":"2025-06-14T12:52:11.099270Z","shell.execute_reply.started":"2025-06-14T12:52:11.099132Z","shell.execute_reply":"2025-06-14T12:52:11.099146Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df=pd.read_csv(\"/kaggle/input/burnout-datathon-ieeecsmuj/train.csv\")\ntest_df=pd.read_csv(\"/kaggle/input/burnout-datathon-ieeecsmuj/test.csv\")\nval_df=pd.read_csv(\"/kaggle/input/burnout-datathon-ieeecsmuj/val.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T12:12:06.126812Z","iopub.execute_input":"2025-06-14T12:12:06.127206Z","iopub.status.idle":"2025-06-14T12:12:21.975465Z","shell.execute_reply.started":"2025-06-14T12:12:06.127182Z","shell.execute_reply":"2025-06-14T12:12:21.974472Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"train_df = pd.concat([train_df, val_df], ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T12:12:21.976902Z","iopub.execute_input":"2025-06-14T12:12:21.977162Z","iopub.status.idle":"2025-06-14T12:12:22.258117Z","shell.execute_reply.started":"2025-06-14T12:12:21.977142Z","shell.execute_reply":"2025-06-14T12:12:22.256935Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.metrics import mean_squared_error\n\n# Define the key columns\noriginal_key_cols = [\n    'rider','circuit_name', 'year_x',\n     'Corners_per_Lap', 'Pit_Stop_Duration_Seconds'\n]\n\n# Make sure all columns are strings\nfor col in original_key_cols:\n    train_df[col] = train_df[col].astype(str)\n    test_df[col] = test_df[col].astype(str)\n\n# Store results\nresults = []\n\n# Loop through each column, remove one at a time\nfor col_to_remove in original_key_cols:\n    reduced_key_cols = [col for col in original_key_cols if col != col_to_remove]\n\n    # Create composite key\n    train_df['key'] = train_df[reduced_key_cols].agg('_'.join, axis=1)\n    test_df['key'] = test_df[reduced_key_cols].agg('_'.join, axis=1)\n\n    # Group mean mapping\n    key_to_avg = train_df.groupby('key')['Lap_Time_Seconds'].mean()\n\n    # Map predictions\n    train_df['calc_lap_time'] = train_df['key'].map(key_to_avg)\n    test_df['calc_lap_time'] = test_df['key'].map(key_to_avg)\n\n    # Metrics\n    rmse = mean_squared_error(train_df['Lap_Time_Seconds'], train_df['calc_lap_time'], squared=False)\n    nan_count = test_df['calc_lap_time'].isna().sum()\n\n    results.append({\n        'Removed_Column': col_to_remove,\n        'NaN_Count_in_Test': nan_count,\n        'Train_RMSE': rmse\n    })\n\n# Convert results to DataFrame\nresults_df = pd.DataFrame(results)\n\n# Show result\nprint(results_df.sort_values(by='Train_RMSE'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T12:52:17.651466Z","iopub.execute_input":"2025-06-14T12:52:17.652236Z","iopub.status.idle":"2025-06-14T12:53:39.799691Z","shell.execute_reply.started":"2025-06-14T12:52:17.652209Z","shell.execute_reply":"2025-06-14T12:53:39.798375Z"}},"outputs":[{"name":"stdout","text":"              Removed_Column  NaN_Count_in_Test  Train_RMSE\n3            Corners_per_Lap                  0    0.130436\n2                     year_x                  0    0.280497\n1               circuit_name                  0    0.336337\n4  Pit_Stop_Duration_Seconds                  0    0.627578\n0                      rider                  0    0.966632\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}