{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c1af2d8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-14T05:50:16.488478Z",
     "iopub.status.busy": "2025-06-14T05:50:16.488262Z",
     "iopub.status.idle": "2025-06-14T05:50:45.085940Z",
     "shell.execute_reply": "2025-06-14T05:50:45.085119Z"
    },
    "papermill": {
     "duration": 28.601633,
     "end_time": "2025-06-14T05:50:45.087346",
     "exception": false,
     "start_time": "2025-06-14T05:50:16.485713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.1/312.1 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.8/234.8 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.12.0 which is incompatible.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# ✅ Install compatible versions of required libraries\n",
    "!pip install -q scikit-learn==1.3.2 autogluon.tabular ray==2.10.0\n",
    "\n",
    "# ✅ Restart the kernel/runtime after running this cell (for local runtime only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e92ba1f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T05:50:45.095469Z",
     "iopub.status.busy": "2025-06-14T05:50:45.095177Z",
     "iopub.status.idle": "2025-06-14T05:51:07.066471Z",
     "shell.execute_reply": "2025-06-14T05:51:07.065768Z"
    },
    "papermill": {
     "duration": 21.976962,
     "end_time": "2025-06-14T05:51:07.068064",
     "exception": false,
     "start_time": "2025-06-14T05:50:45.091102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    train_path = \"/kaggle/input/burnout-datathon-ieeecsmuj/train.csv\"\n",
    "    test_path = \"/kaggle/input/burnout-datathon-ieeecsmuj/test.csv\"\n",
    "    sample_sub_path = \"/kaggle/input/burnout-datathon-ieeecsmuj/sample_submission.csv\"\n",
    "    val_path=\"/kaggle/input/burnout-datathon-ieeecsmuj/val.csv\"\n",
    "    \n",
    "    target = 'Lap_Time_Seconds'\n",
    "    n_folds = 5\n",
    "    seed = 1859\n",
    "    time_limit = 3600 * 2  # adjust if needed\n",
    "\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv(CFG.train_path)\n",
    "test = pd.read_csv(CFG.test_path)\n",
    "val = pd.read_csv(CFG.val_path)\n",
    "\n",
    "train = pd.concat([train, val], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47298fa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T05:51:07.076641Z",
     "iopub.status.busy": "2025-06-14T05:51:07.076391Z",
     "iopub.status.idle": "2025-06-14T07:51:12.157427Z",
     "shell.execute_reply": "2025-06-14T07:51:12.156570Z"
    },
    "papermill": {
     "duration": 7205.086577,
     "end_time": "2025-06-14T07:51:12.158693",
     "exception": false,
     "start_time": "2025-06-14T05:51:07.072116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250614_055107\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sun Nov 10 10:07:59 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       28.28 GB / 31.35 GB (90.2%)\n",
      "Disk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=0, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 7200s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20250614_055107\"\n",
      "Train Data Rows:    2187493\n",
      "Train Data Columns: 44\n",
      "Label Column:       Lap_Time_Seconds\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30380.12 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2217.45 MB (7.3% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 7.3% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['team_name']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 6\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 6 to 3 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        :  7 | ['Circuit_Length_km', 'Avg_Speed_kmh', 'points', 'Tire_Degradation_Factor_per_Lap', 'Pit_Stop_Duration_Seconds', ...]\n",
      "\t\t('int', [])          : 24 | ['Unique ID', 'Rider_ID', 'Laps', 'Grid_Position', 'Humidity_%', ...]\n",
      "\t\t('object', [])       : 12 | ['category_x', 'Track_Condition', 'Tire_Compound_Front', 'Tire_Compound_Rear', 'Penalty', ...]\n",
      "\t\t('object', ['text']) :  1 | ['team_name']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    : 10 | ['category_x', 'Tire_Compound_Front', 'Tire_Compound_Rear', 'Penalty', 'Session', ...]\n",
      "\t\t('category', ['text_as_category'])  :  1 | ['team_name']\n",
      "\t\t('float', [])                       :  7 | ['Circuit_Length_km', 'Avg_Speed_kmh', 'points', 'Tire_Degradation_Factor_per_Lap', 'Pit_Stop_Duration_Seconds', ...]\n",
      "\t\t('int', [])                         : 24 | ['Unique ID', 'Rider_ID', 'Laps', 'Grid_Position', 'Humidity_%', ...]\n",
      "\t\t('int', ['binned', 'text_special']) : 12 | ['team_name.char_count', 'team_name.word_count', 'team_name.capital_ratio', 'team_name.lower_ratio', 'team_name.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :  2 | ['Track_Condition', 'track']\n",
      "\t\t('int', ['text_ngram'])             :  4 | ['__nlp__.racing', '__nlp__.racing team', '__nlp__.team', '__nlp__._total_']\n",
      "\t62.1s = Fit runtime\n",
      "\t44 features in original data used to generate 60 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 592.47 MB (2.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 64.74s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 2165618, Val Rows: 21875\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 108 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 7135.26s of the 7135.25s of remaining time.\n",
      "\t-12.6795\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.68s\t = Training   runtime\n",
      "\t34.86s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 7092.52s of the 7092.51s of remaining time.\n",
      "\t-13.2208\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.06s\t = Training   runtime\n",
      "\t32.72s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 7052.55s of the 7052.55s of remaining time.\n",
      "\tTraining LightGBMXT with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] bin size 1987 cannot run on GPU\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 9.13899\n",
      "[2000]\tvalid_set's rmse: 7.63927\n",
      "[3000]\tvalid_set's rmse: 6.59858\n",
      "[4000]\tvalid_set's rmse: 5.76337\n",
      "[5000]\tvalid_set's rmse: 5.05678\n",
      "[6000]\tvalid_set's rmse: 4.44246\n",
      "[7000]\tvalid_set's rmse: 3.88599\n",
      "[8000]\tvalid_set's rmse: 3.43531\n",
      "[9000]\tvalid_set's rmse: 3.05222\n",
      "[10000]\tvalid_set's rmse: 2.72002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.72\t = Validation score   (-root_mean_squared_error)\n",
      "\t1241.6s\t = Training   runtime\n",
      "\t7.41s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 5802.25s of the 5802.24s of remaining time.\n",
      "\tTraining LightGBM with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "[LightGBM] [Fatal] bin size 1987 cannot run on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 7.81052\n",
      "[2000]\tvalid_set's rmse: 6.05369\n",
      "[3000]\tvalid_set's rmse: 4.77096\n",
      "[4000]\tvalid_set's rmse: 3.80214\n",
      "[5000]\tvalid_set's rmse: 2.99271\n",
      "[6000]\tvalid_set's rmse: 2.38741\n",
      "[7000]\tvalid_set's rmse: 1.93856\n",
      "[8000]\tvalid_set's rmse: 1.61369\n",
      "[9000]\tvalid_set's rmse: 1.32332\n",
      "[10000]\tvalid_set's rmse: 1.10505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-1.105\t = Validation score   (-root_mean_squared_error)\n",
      "\t1347.73s\t = Training   runtime\n",
      "\t7.06s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 4446.03s of the 4446.02s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 126 due to low time. Expected time usage reduced from 10531.9s -> 4446.0s...\n",
      "\t-1.4003\t = Validation score   (-root_mean_squared_error)\n",
      "\t4238.34s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 207.08s of the 207.08s of remaining time.\n",
      "\tTraining CatBoost with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-11.4061\t = Validation score   (-root_mean_squared_error)\n",
      "\t42.31s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 164.75s of the 164.74s of remaining time.\n",
      "\tWarning: Model is expected to require 4030.6s to train, which exceeds the maximum time limit of 164.7s, skipping model...\n",
      "\tTime limit exceeded... Skipping ExtraTreesMSE.\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 108.78s of the 108.78s of remaining time.\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 1)\n",
      "\tWarning: Exception caused NeuralNetFastAI to fail during training... Skipping this model.\n",
      "\t\tException occured in `AgSaveModelCallback` when calling event `after_fit`:\n",
      "\tWeights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
      "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
      "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
      "\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n",
      "\n",
      "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 359, in _fit\n",
      "    self.model.fit_one_cycle(epochs, params[\"lr\"], cbs=callbacks)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/fastai/callback/schedule.py\", line 121, in fit_one_cycle\n",
      "    self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd, start_epoch=start_epoch)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/fastai/learner.py\", line 272, in fit\n",
      "    self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/fastai/learner.py\", line 209, in _with_events\n",
      "    self(f'after_{event_type}');  final()\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/fastai/learner.py\", line 180, in __call__\n",
      "    def __call__(self, event_name): L(event_name).map(self._call_one)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/fastcore/foundation.py\", line 163, in map\n",
      "    def map(self, f, *args, **kwargs): return self._new(map_ex(self, f, *args, gen=False, **kwargs))\n",
      "                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/fastcore/basics.py\", line 934, in map_ex\n",
      "    return list(res)\n",
      "           ^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/fastcore/basics.py\", line 919, in __call__\n",
      "    return self.func(*fargs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/fastai/learner.py\", line 184, in _call_one\n",
      "    for cb in self.cbs.sorted('order'): cb(event_name)\n",
      "                                        ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/fastai/callback/core.py\", line 64, in __call__\n",
      "    except Exception as e: raise modify_exception(e, f'Exception occured in `{self.__class__.__name__}` when calling event `{event_name}`:\\n\\t{e.args[0]}', replace=True)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/fastai/callback/core.py\", line 62, in __call__\n",
      "    try: res = getcallable(self, event_name)()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/callbacks.py\", line 115, in after_fit\n",
      "    self.learn.load(f\"{self.fname}\", with_opt=self.with_opt)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/fastai/learner.py\", line 428, in load\n",
      "    load_model(file, self.model, self.opt, device=device, **kwargs)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/fastai/learner.py\", line 59, in load_model\n",
      "    state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 1470, in load\n",
      "    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n",
      "_pickle.UnpicklingError: Exception occured in `AgSaveModelCallback` when calling event `after_fit`:\n",
      "\tWeights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
      "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
      "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
      "\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n",
      "\n",
      "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 713.53s of the -2.06s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM': 0.714, 'RandomForestMSE': 0.286}\n",
      "\t-1.0386\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 7204.16s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2964.2 rows/s (21875 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20250614_055107\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x79381ce10110>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[CFG.target] = train[CFG.target].astype(float)\n",
    "\n",
    "# Create fold column (not needed by AutoGluon but useful for tracking)\n",
    "kf = KFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n",
    "for i, (_, val_idx) in enumerate(kf.split(train)):\n",
    "    train.loc[val_idx, 'fold'] = i\n",
    "\n",
    "# Initialize TabularPredictor for regression\n",
    "predictor = TabularPredictor(\n",
    "    label=CFG.target,\n",
    "    problem_type='regression',\n",
    "    eval_metric='rmse',\n",
    "    verbosity=2\n",
    ")\n",
    "\n",
    "predictor.fit(\n",
    "    train_data=train.drop(columns=[\"fold\"]),\n",
    "    time_limit=CFG.time_limit,\n",
    "    presets='best_quality',\n",
    "    ag_args_fit={\n",
    "        'num_gpus': 1,\n",
    "        'num_cpus': 4\n",
    "    },\n",
    "    # Disable stacking\n",
    "    use_bag_holdout=False,     # no internal holdout set for bagging\n",
    "    num_bag_folds=0,           # disables bagging\n",
    "    num_stack_levels=0         # disables stacking\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0773f897",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T07:51:12.176216Z",
     "iopub.status.busy": "2025-06-14T07:51:12.175705Z",
     "iopub.status.idle": "2025-06-14T07:51:12.245200Z",
     "shell.execute_reply": "2025-06-14T07:51:12.244400Z"
    },
    "papermill": {
     "duration": 0.079303,
     "end_time": "2025-06-14T07:51:12.246388",
     "exception": false,
     "start_time": "2025-06-14T07:51:12.167085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e8dad_row0_col1 {\n",
       "  background-color: #006837;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e8dad_row1_col1 {\n",
       "  background-color: #016a38;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e8dad_row2_col1 {\n",
       "  background-color: #07753e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e8dad_row3_col1 {\n",
       "  background-color: #36a657;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e8dad_row4_col1 {\n",
       "  background-color: #e54e35;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e8dad_row5_col1 {\n",
       "  background-color: #bb1526;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e8dad_row6_col1 {\n",
       "  background-color: #a50026;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e8dad\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e8dad_level0_col0\" class=\"col_heading level0 col0\" >model</th>\n",
       "      <th id=\"T_e8dad_level0_col1\" class=\"col_heading level0 col1\" >score_val</th>\n",
       "      <th id=\"T_e8dad_level0_col2\" class=\"col_heading level0 col2\" >eval_metric</th>\n",
       "      <th id=\"T_e8dad_level0_col3\" class=\"col_heading level0 col3\" >pred_time_val</th>\n",
       "      <th id=\"T_e8dad_level0_col4\" class=\"col_heading level0 col4\" >fit_time</th>\n",
       "      <th id=\"T_e8dad_level0_col5\" class=\"col_heading level0 col5\" >pred_time_val_marginal</th>\n",
       "      <th id=\"T_e8dad_level0_col6\" class=\"col_heading level0 col6\" >fit_time_marginal</th>\n",
       "      <th id=\"T_e8dad_level0_col7\" class=\"col_heading level0 col7\" >stack_level</th>\n",
       "      <th id=\"T_e8dad_level0_col8\" class=\"col_heading level0 col8\" >can_infer</th>\n",
       "      <th id=\"T_e8dad_level0_col9\" class=\"col_heading level0 col9\" >fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e8dad_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e8dad_row0_col0\" class=\"data row0 col0\" >WeightedEnsemble_L2</td>\n",
       "      <td id=\"T_e8dad_row0_col1\" class=\"data row0 col1\" >-1.038618</td>\n",
       "      <td id=\"T_e8dad_row0_col2\" class=\"data row0 col2\" >root_mean_squared_error</td>\n",
       "      <td id=\"T_e8dad_row0_col3\" class=\"data row0 col3\" >7.379686</td>\n",
       "      <td id=\"T_e8dad_row0_col4\" class=\"data row0 col4\" >5586.111612</td>\n",
       "      <td id=\"T_e8dad_row0_col5\" class=\"data row0 col5\" >0.007704</td>\n",
       "      <td id=\"T_e8dad_row0_col6\" class=\"data row0 col6\" >0.038600</td>\n",
       "      <td id=\"T_e8dad_row0_col7\" class=\"data row0 col7\" >2</td>\n",
       "      <td id=\"T_e8dad_row0_col8\" class=\"data row0 col8\" >True</td>\n",
       "      <td id=\"T_e8dad_row0_col9\" class=\"data row0 col9\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e8dad_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e8dad_row1_col0\" class=\"data row1 col0\" >LightGBM</td>\n",
       "      <td id=\"T_e8dad_row1_col1\" class=\"data row1 col1\" >-1.105046</td>\n",
       "      <td id=\"T_e8dad_row1_col2\" class=\"data row1 col2\" >root_mean_squared_error</td>\n",
       "      <td id=\"T_e8dad_row1_col3\" class=\"data row1 col3\" >7.057517</td>\n",
       "      <td id=\"T_e8dad_row1_col4\" class=\"data row1 col4\" >1347.732150</td>\n",
       "      <td id=\"T_e8dad_row1_col5\" class=\"data row1 col5\" >7.057517</td>\n",
       "      <td id=\"T_e8dad_row1_col6\" class=\"data row1 col6\" >1347.732150</td>\n",
       "      <td id=\"T_e8dad_row1_col7\" class=\"data row1 col7\" >1</td>\n",
       "      <td id=\"T_e8dad_row1_col8\" class=\"data row1 col8\" >True</td>\n",
       "      <td id=\"T_e8dad_row1_col9\" class=\"data row1 col9\" >4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e8dad_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e8dad_row2_col0\" class=\"data row2 col0\" >RandomForestMSE</td>\n",
       "      <td id=\"T_e8dad_row2_col1\" class=\"data row2 col1\" >-1.400302</td>\n",
       "      <td id=\"T_e8dad_row2_col2\" class=\"data row2 col2\" >root_mean_squared_error</td>\n",
       "      <td id=\"T_e8dad_row2_col3\" class=\"data row2 col3\" >0.314465</td>\n",
       "      <td id=\"T_e8dad_row2_col4\" class=\"data row2 col4\" >4238.340862</td>\n",
       "      <td id=\"T_e8dad_row2_col5\" class=\"data row2 col5\" >0.314465</td>\n",
       "      <td id=\"T_e8dad_row2_col6\" class=\"data row2 col6\" >4238.340862</td>\n",
       "      <td id=\"T_e8dad_row2_col7\" class=\"data row2 col7\" >1</td>\n",
       "      <td id=\"T_e8dad_row2_col8\" class=\"data row2 col8\" >True</td>\n",
       "      <td id=\"T_e8dad_row2_col9\" class=\"data row2 col9\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e8dad_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e8dad_row3_col0\" class=\"data row3 col0\" >LightGBMXT</td>\n",
       "      <td id=\"T_e8dad_row3_col1\" class=\"data row3 col1\" >-2.720016</td>\n",
       "      <td id=\"T_e8dad_row3_col2\" class=\"data row3 col2\" >root_mean_squared_error</td>\n",
       "      <td id=\"T_e8dad_row3_col3\" class=\"data row3 col3\" >7.406538</td>\n",
       "      <td id=\"T_e8dad_row3_col4\" class=\"data row3 col4\" >1241.602279</td>\n",
       "      <td id=\"T_e8dad_row3_col5\" class=\"data row3 col5\" >7.406538</td>\n",
       "      <td id=\"T_e8dad_row3_col6\" class=\"data row3 col6\" >1241.602279</td>\n",
       "      <td id=\"T_e8dad_row3_col7\" class=\"data row3 col7\" >1</td>\n",
       "      <td id=\"T_e8dad_row3_col8\" class=\"data row3 col8\" >True</td>\n",
       "      <td id=\"T_e8dad_row3_col9\" class=\"data row3 col9\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e8dad_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e8dad_row4_col0\" class=\"data row4 col0\" >CatBoost</td>\n",
       "      <td id=\"T_e8dad_row4_col1\" class=\"data row4 col1\" >-11.406137</td>\n",
       "      <td id=\"T_e8dad_row4_col2\" class=\"data row4 col2\" >root_mean_squared_error</td>\n",
       "      <td id=\"T_e8dad_row4_col3\" class=\"data row4 col3\" >0.022169</td>\n",
       "      <td id=\"T_e8dad_row4_col4\" class=\"data row4 col4\" >42.306201</td>\n",
       "      <td id=\"T_e8dad_row4_col5\" class=\"data row4 col5\" >0.022169</td>\n",
       "      <td id=\"T_e8dad_row4_col6\" class=\"data row4 col6\" >42.306201</td>\n",
       "      <td id=\"T_e8dad_row4_col7\" class=\"data row4 col7\" >1</td>\n",
       "      <td id=\"T_e8dad_row4_col8\" class=\"data row4 col8\" >True</td>\n",
       "      <td id=\"T_e8dad_row4_col9\" class=\"data row4 col9\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e8dad_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_e8dad_row5_col0\" class=\"data row5 col0\" >KNeighborsUnif</td>\n",
       "      <td id=\"T_e8dad_row5_col1\" class=\"data row5 col1\" >-12.679524</td>\n",
       "      <td id=\"T_e8dad_row5_col2\" class=\"data row5 col2\" >root_mean_squared_error</td>\n",
       "      <td id=\"T_e8dad_row5_col3\" class=\"data row5 col3\" >34.861209</td>\n",
       "      <td id=\"T_e8dad_row5_col4\" class=\"data row5 col4\" >5.675828</td>\n",
       "      <td id=\"T_e8dad_row5_col5\" class=\"data row5 col5\" >34.861209</td>\n",
       "      <td id=\"T_e8dad_row5_col6\" class=\"data row5 col6\" >5.675828</td>\n",
       "      <td id=\"T_e8dad_row5_col7\" class=\"data row5 col7\" >1</td>\n",
       "      <td id=\"T_e8dad_row5_col8\" class=\"data row5 col8\" >True</td>\n",
       "      <td id=\"T_e8dad_row5_col9\" class=\"data row5 col9\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e8dad_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_e8dad_row6_col0\" class=\"data row6 col0\" >KNeighborsDist</td>\n",
       "      <td id=\"T_e8dad_row6_col1\" class=\"data row6 col1\" >-13.220800</td>\n",
       "      <td id=\"T_e8dad_row6_col2\" class=\"data row6 col2\" >root_mean_squared_error</td>\n",
       "      <td id=\"T_e8dad_row6_col3\" class=\"data row6 col3\" >32.719030</td>\n",
       "      <td id=\"T_e8dad_row6_col4\" class=\"data row6 col4\" >5.063935</td>\n",
       "      <td id=\"T_e8dad_row6_col5\" class=\"data row6 col5\" >32.719030</td>\n",
       "      <td id=\"T_e8dad_row6_col6\" class=\"data row6 col6\" >5.063935</td>\n",
       "      <td id=\"T_e8dad_row6_col7\" class=\"data row6 col7\" >1</td>\n",
       "      <td id=\"T_e8dad_row6_col8\" class=\"data row6 col8\" >True</td>\n",
       "      <td id=\"T_e8dad_row6_col9\" class=\"data row6 col9\" >2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7937f84d5090>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(silent=True).style.background_gradient(subset=['score_val'], cmap='RdYlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fb01046",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T07:51:12.263997Z",
     "iopub.status.busy": "2025-06-14T07:51:12.263736Z",
     "iopub.status.idle": "2025-06-14T07:54:16.590774Z",
     "shell.execute_reply": "2025-06-14T07:54:16.590080Z"
    },
    "papermill": {
     "duration": 184.345553,
     "end_time": "2025-06-14T07:54:16.600496",
     "exception": false,
     "start_time": "2025-06-14T07:51:12.254943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Submission file saved as 'submission_autogluon.csv'\n"
     ]
    }
   ],
   "source": [
    "cols_to_drop = \"Lap_Time_Seconds\"\n",
    "\n",
    "# Drop target column from test if present\n",
    "if cols_to_drop in test.columns:\n",
    "    test.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# Predict with AutoGluon predictor\n",
    "pred = predictor.predict(test)\n",
    "\n",
    "# Add predictions back to test\n",
    "test[\"Lap_Time_Seconds\"] = pred\n",
    "\n",
    "# Save submission file\n",
    "submission = test[[\"Lap_Time_Seconds\"]]\n",
    "submission.to_csv(\"submission_autogluon.csv\", index=False)\n",
    "print(\"✅ Submission file saved as 'submission_autogluon.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12651513,
     "sourceId": 104857,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7447.789701,
   "end_time": "2025-06-14T07:54:19.806175",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-14T05:50:12.016474",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
